{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a019a811-12c2-4651-945d-b7691556e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8065843621399177\n",
      "Initial:\n",
      "Precision: 1.0\n",
      "Recall: 0.04081632653061224\n",
      "\n",
      "Average Number of Non-Students Added:\n",
      "Average for 5% drop: 96.0\n",
      "Average for 10% drop: 106.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "def calculate_explanation_complexity(answer):\n",
    "  if isinstance(answer, str):\n",
    "    unique_words = set(answer.split(' '))\n",
    "    word_count = len(answer.split(' '))\n",
    "    return len(unique_words) / word_count\n",
    "  return 0\n",
    "\n",
    "def calculate_explanation_size(answer):\n",
    "  if isinstance(answer, str):\n",
    "    return len(answer)\n",
    "  return 0\n",
    "\n",
    "# Input: participant score and profession, duration, explanation size/complexity, confidence and difficulty\n",
    "# Output: label answer as correct or incorrect\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "data['Answer.complexity'] = data['Answer.explanation'].apply(calculate_explanation_complexity)\n",
    "data['Answer.size'] = data['Answer.explanation'].apply(calculate_explanation_size)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['Worker.profession_encoded'] =  encoder.fit_transform(data['Worker.profession'])\n",
    "\n",
    "student = ['Undergraduate_Student', 'Graduate_Student']\n",
    "non_student = ['Professional_Developer', 'Hobbyist', 'Other']\n",
    "\n",
    "student_set = data[data['Worker.profession'].isin(student)]\n",
    "\n",
    "\n",
    "#train = student_set[student_set['Worker.profession'] == 'Undergraduate_Student']\n",
    "#holdout = student_set[student_set['Worker.profession'] == 'Graduate_Student']\n",
    "\n",
    "train, holdout = train_test_split(student_set, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train = train[['Worker.score', 'Worker.profession_encoded', 'Answer.duration', 'Answer.size', 'Answer.complexity', 'Answer.confidence', 'Answer.difficulty']]\n",
    "y_train = train['GroundTruth']\n",
    "\n",
    "X_holdout = holdout[['Worker.score', 'Worker.profession_encoded', 'Answer.duration', 'Answer.size', 'Answer.complexity', 'Answer.confidence', 'Answer.difficulty']]\n",
    "y_holdout = holdout['GroundTruth']\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy score: \", clf.score(X_holdout, y_holdout))\n",
    "\n",
    "y_predict = clf.predict(X_holdout)\n",
    "initial_precision = precision_score(y_holdout, y_predict)\n",
    "initial_recall = recall_score(y_holdout, y_predict)\n",
    "\n",
    "print(\"Initial:\")\n",
    "print(f\"Precision: {initial_precision}\")\n",
    "print(f\"Recall: {initial_recall}\")\n",
    "\n",
    "non_student_set = data[data['Worker.profession'].isin(non_student)]\n",
    "\n",
    "thresholds = {\n",
    "    'precision_5': None,\n",
    "    'precision_10': None,\n",
    "    'recall_5': None,\n",
    "    'recall_10': None\n",
    "}\n",
    "\n",
    "for i in range(1, len(non_student_set) + 1):\n",
    "    sampled_non_students = non_student_set.sample(i, random_state=42)\n",
    "    new_holdout = pd.concat([holdout, sampled_non_students], ignore_index=True)\n",
    "\n",
    "    X_holdout = new_holdout[['Worker.score', 'Worker.profession_encoded', 'Answer.duration', 'Answer.size', 'Answer.complexity', 'Answer.confidence', 'Answer.difficulty']]\n",
    "    y_holdout = new_holdout['GroundTruth']\n",
    "\n",
    "    y_predict = clf.predict(X_holdout)\n",
    "\n",
    "    current_precision = precision_score(y_holdout, y_predict)\n",
    "    current_recall = recall_score(y_holdout, y_predict)\n",
    "\n",
    "    if thresholds['precision_5'] is None and (initial_precision - current_precision) / initial_precision >= 0.05:\n",
    "        thresholds['precision_5'] = i\n",
    "    if thresholds['precision_10'] is None and (initial_precision - current_precision) / initial_precision >= 0.10:\n",
    "        thresholds['precision_10'] = i\n",
    "    if thresholds['recall_5'] is None and (initial_recall - current_recall) / initial_recall >= 0.05:\n",
    "        thresholds['recall_5'] = i\n",
    "    if thresholds['recall_10'] is None and (initial_recall - current_recall) / initial_recall >= 0.10:\n",
    "        thresholds['recall_10'] = i\n",
    "\n",
    "    if all(value is not None for value in thresholds.values()):\n",
    "        break\n",
    "\n",
    "avg_drop_5 = (thresholds['precision_5'] + thresholds['recall_5']) / 2 if thresholds['precision_5'] and thresholds['recall_5'] else None\n",
    "avg_drop_10 = (thresholds['precision_10'] + thresholds['recall_10']) / 2 if thresholds['precision_10'] and thresholds['recall_10'] else None\n",
    "\n",
    "print(\"\\nAverage Number of Non-Students Added:\")\n",
    "if avg_drop_5 is not None:\n",
    "    print(f\"Average for 5% drop: {avg_drop_5}\")\n",
    "else:\n",
    "    print(\"5% drop not observed for both metrics.\")\n",
    "\n",
    "if avg_drop_10 is not None:\n",
    "    print(f\"Average for 10% drop: {avg_drop_10}\")\n",
    "else:\n",
    "    print(\"10% drop not observed for both metrics.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d9fe4b-33be-42c3-9070-b5d2801aa290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum Non-Student Size to have same outcome with old model: 0\n"
     ]
    }
   ],
   "source": [
    "# Previous model recall and precisions:\n",
    "old_model_precision = 0.9711286089238845\n",
    "old_model_recall = 0.8809523809523809\n",
    "\n",
    "min_non_student_size = 0\n",
    "\n",
    "for i in range(1, len(non_student_set) + 1):\n",
    "    sampled_non_students = non_student_set.sample(i, random_state=42)\n",
    "    new_holdout = pd.concat([holdout, sampled_non_students], ignore_index=True)\n",
    "\n",
    "    X_holdout = new_holdout[['Worker.score', 'Worker.profession_encoded', 'Answer.duration', 'Answer.size', 'Answer.complexity', 'Answer.confidence', 'Answer.difficulty']]\n",
    "    y_holdout = new_holdout['GroundTruth']\n",
    "\n",
    "    y_predict = clf.predict(X_holdout)\n",
    "\n",
    "    current_precision = precision_score(y_holdout, y_predict)\n",
    "    current_recall = recall_score(y_holdout, y_predict)\n",
    "\n",
    "    if abs(current_precision - old_model_precision) / old_model_precision <= 0.2 and abs(current_recall - old_model_recall) / old_model_recall <= 0.2:\n",
    "        min_non_student_size = i\n",
    "        break\n",
    "\n",
    "print(\"\\nMinimum Non-Student Size to have same outcome with old model:\", min_non_student_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dbf3a3-f8ee-421f-ab84-6509eff69865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
