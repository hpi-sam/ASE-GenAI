{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5c4487-feba-436c-837b-6c8621ba6b6c",
   "metadata": {
    "id": "9b5c4487-feba-436c-837b-6c8621ba6b6c",
    "outputId": "54c2f566-3c97-4955-cea5-e836ed99852f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diversity Metrics (Entropy) for Filtered Data:\n",
      " - Worker.profession: 1.379\n",
      " - Worker.gender: 0.464\n",
      " - Worker.country: 1.565\n",
      " - Worker.programmingLanguage: 3.395\n",
      "\n",
      "Max readability in dataset: 206.84\n",
      "Max semantic similarity in dataset: 0.856\n",
      "\n",
      "Diversity metrics for answers with near-max semantic similarity:\n",
      " - Worker.profession: 0.662\n",
      " - Worker.gender: -0.000\n",
      " - Worker.country: 0.900\n",
      " - Worker.programmingLanguage: 1.494\n",
      "\n",
      "Diverse explanations saved to 'diverse_explanations.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "raw_data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "ground_truth_df = pd.read_csv(\"ground_truths_per_failing_method_llm.csv\")\n",
    "\n",
    "ground_truth_df = ground_truth_df.rename(columns={'Explanation': 'ground_truth_explanation'})\n",
    "\n",
    "marged_data = pd.merge(raw_data, ground_truth_df[['FailingMethod', 'ground_truth_explanation']],\n",
    "              on='FailingMethod', how='left')\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "gt_embeddings = {}\n",
    "for _, row in ground_truth_df.iterrows():\n",
    "    method = row['FailingMethod']\n",
    "    gt_text = row['ground_truth_explanation']\n",
    "    gt_embeddings[method] = embedding_model.encode(gt_text, convert_to_tensor=False)\n",
    "\n",
    "def compute_readability(text):\n",
    "    try:\n",
    "        return textstat.flesch_reading_ease(str(text))\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def compute_similarity(answer_text, gt_emb):\n",
    "    try:\n",
    "        answer_emb = embedding_model.encode(str(answer_text), convert_to_tensor=False)\n",
    "        return cosine_similarity([answer_emb], [gt_emb])[0][0]\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "marged_data['readability'] = marged_data['Answer.explanation'].apply(compute_readability)\n",
    "marged_data['similarity'] = marged_data.apply(lambda row: compute_similarity(row['Answer.explanation'],\n",
    "                                                          gt_embeddings.get(row['FailingMethod'], None)),\n",
    "                            axis=1)\n",
    "MIN_READABILITY = 40\n",
    "MIN_SIMILARITY = 0.7\n",
    "\n",
    "filtered_df = marged_data[(marged_data['readability'] >= MIN_READABILITY) & (marged_data['similarity'] >= MIN_SIMILARITY)]\n",
    "\n",
    "def shannon_entropy(series):\n",
    "    counts = series.value_counts()\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log(probabilities))\n",
    "\n",
    "\n",
    "diversity_columns = ['Worker.profession', 'Worker.gender', 'Worker.country', 'Worker.programmingLanguage']\n",
    "\n",
    "print(\"\\nDiversity Metrics (Entropy) for Filtered Data:\")\n",
    "for col in diversity_columns:\n",
    "    if col in filtered_df.columns:\n",
    "        entropy_val = shannon_entropy(filtered_df[col])\n",
    "        print(f\" - {col}: {entropy_val:.3f}\")\n",
    "\n",
    "\n",
    "if all(col in filtered_df.columns for col in diversity_columns):\n",
    "    diverse_subset = (filtered_df.groupby(diversity_columns)\n",
    "                      .apply(lambda g: g.sort_values(by='similarity', ascending=False).iloc[0])\n",
    "                      .reset_index(drop=True))\n",
    "else:\n",
    "    diverse_subset = filtered_df.copy()\n",
    "\n",
    "max_readability = marged_data['readability'].max()\n",
    "max_similarity = marged_data['similarity'].max()\n",
    "print(f\"\\nMax readability in dataset: {max_readability:.2f}\")\n",
    "print(f\"Max semantic similarity in dataset: {max_similarity:.3f}\")\n",
    "\n",
    "\n",
    "similarity_threshold_near_max = max_similarity * 0.95\n",
    "near_max_df = marged_data[marged_data['similarity'] >= similarity_threshold_near_max]\n",
    "\n",
    "print(\"\\nDiversity metrics for answers with near-max semantic similarity:\")\n",
    "for col in diversity_columns:\n",
    "    if col in near_max_df.columns:\n",
    "        entropy_val = shannon_entropy(near_max_df[col])\n",
    "        print(f\" - {col}: {entropy_val:.3f}\")\n",
    "\n",
    "output_filename = \"diverse_explanations.csv\"\n",
    "diverse_subset.to_csv(output_filename, index=False)\n",
    "print(f\"\\nDiverse explanations saved to '{output_filename}'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
