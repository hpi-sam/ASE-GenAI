{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Diverse Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Minutes are set to -15; which is less then 0 and it throws illegal arg exception', 'The code never gets that far. The problem is at line 279 which prevents a negative minutes value being accepted even though the programmer comments indicate that since version 2.3 negative minutes up to -59 are acceptable. The @throws IllegalArgumentException comment is also referring to versions before 2.3.', 'In the code there is a check that 0 <= minutes < 60 and the minutesOffset is -15 which does not fall into these prarmeters thus throwing an Exception', 'There is a logical check for if minuteOffset is less than 0 or greater than 59 causing it to throw an exception because the value is out of bounds (negative number)', 'YES. The issue is on line 279 (as I explained in my first question; of which I misunderstood that I was only being asked about the specific issue; not generalized issue). On line 279 the variable \"minutesOffSet\" is parameterized to throw an exception if it is < 0 or > 59. Line 279 should read \"if (minutesOffset < -59 || minutesOffset > 59) {\" because now the method can take in the number of minutes as a negative and will allow the method to properly progress to invoke/call further methods such as those asked about in the two previous questions.', 'The variable \"minutesOffset\" is checked incorrectly by the IF statement on line 279. Any negative value for \"minutesOffset\" will throw this exception; while the documentation states that \"minutesOffset\" can be negative in some cases.', \"Again the issue remains that the parameter check for minutes at line 279 doesn't allow negative numbers  and thus throws the exception.  This needs to be changed to allow up to -59 (but only if hour is positive) if the comments are up to date ... plus possibly later code as well; but certainly that for starters. \", 'This variable contains a value of -15 as set by DateTimeZone.forOffsetHoursMinutes(-2; -15). Line 279 checks to see if is a valid value; meaning that is between 0 and 59. Since it is not; an exception error is thrown in line 280.', 'Yes; the variable gets set to -15 through the arguments above. The code specifically encounters the error on line 279 when it tests if minutesOffset < 0; (-15) which is the case; so it throws the error on line 280 : Minutes out of range: with the value provided for that argument -15.', 'As noted in the comments; valid input for minutes must be in the rage -59 to +59 but on line 279 of the source minutesOffset is checked for < 0. Instead it should be minutesOFfset < -59 . Also noted in comments is that versions before 2.3 minutes had to be zero or positive. \"Minutes out of range: + minutesOffset\" is our error.', 'the variable should be defined as \"unsigned int\" if we expect it to be always positive', 'minutesOffset it is the offset in minutes from UTC; must be between 0 and 59 inclusive ', 'this is also an int; which is a signed value.', 'The second argument should be just 15', 'The value of minutes offset does not have valid argument as a result this method will not be called as and argument exception will be displayed.', \"yep; they are checking if minutesOffset < 0 to throw an exception; and as -15 <0; it gets thrown. looks like they updated the comments but not the code. and this is why comments are evil liars that can't be trusted!\", 'The error is stemming from line 279 because the value of -15 for minutesOffset is < 0. The line should be     if (minutesOffset < -59 || minutesOffset > 59) {', 'The definition seems fine to me. ', 'There should be no issue with the variable minutesOffset; as it was declared properly and should not be related to the failure when it was being used in the correct manner. minutesOffset is of type int; but it is not being miscalled anywhere in the source code.', 'I believe the issue is with hoursOffset not minutes', 'The minute variable was negative therefore; it threw the exception because it only takes numbers between 0 and 59 for minutes.', 'the conditional clause throws an error if the value of minutes is smaller than zero', 'The argument -15 is less than 0; which causes the if statement conditional on line 279 to pass. This results in the exception on line 280 being thrown. According to the comment block above the method; minutesOffset should be checked for below -59 or above 59.', 'There may be an issue as it involves not indigenous java', 'According to the comments; the minute value should be between -59 and +59; but the conditional statement is checking for a value between 0 and 59.', 'There is not an issue with this portion of the code; in fact this is where the exception we receive is thrown.  Therefore the issue probably occurs before we reach this part of the code; such as when the arguments are passed into the method.', 'Yes; this line is exactly the one that produces the exception when minutesOffset is <0. As minutesOffset; being the second argument in the function; gets the value -15 in the call to DateTimeZone.forOffsetHoursMinutes(-2; -15)', 'You are passing it a negative offset value (-15) and the conditionals are set to reject any offset that is less than 0 or greater than 59 and throw a new exception.', 'the code is incomplete. it properly checks for greater than 59 but neglects to take into account if the hours are negative before rejecting minutes for being negative. it would be more correct though not completely to check for less than -59 instead of less than 0', 'It will return the offset', 'am not good in thus questanaire', 'Line 279 written as \"minutesOffset < 0\" makes it clear it\\'s the one throwing the Exception; as the -15 in the minutes spot is clearly less than 0.', 'this cause assumes all negative minutes are bad. from the comment; negative minutes are ok when the hours are negative too. the comments specifically say its bad when the mins are negative but the hours are positive. there is a line break in the middle of that part of the comment which could lead a programmer to miss half of the info.', 'Yes ; this conditional clause is exactly the place from where the exception is thrown ; because it is not in valid range of \"minutes\"', \"It's because of second line negative value.\", 'This conditional will reject any negative minute input; even if the hour input is also negative.', 'This is the argument exception thrown.', '-15 is less then 0; so it throws IllegalArgumentException', 'Value passed in minutes -15;where as it checks (<0 | >53).', 'DateTimeZone.forOffsetHoursMinutes(-2; -15) is an invalid argument so it will directly throw an exception. Hence there is no issue between the conditional statement.']\n"
     ]
    }
   ],
   "source": [
    "# Load bug reports explanations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"../../data/answerList_data.csv\")\n",
    "\n",
    "bug_reports_data = {}\n",
    "\n",
    "# read one file per failing method\n",
    "for failing_method in data['FailingMethod'].unique():\n",
    "    with open(Path(f\"../exercise2/{failing_method}.txt\"), 'r') as f:\n",
    "        # individual explanations are separated by a newline\n",
    "        explanations = f.read().split(\"\\n\")\n",
    "        explanations = [explanation for explanation in explanations if explanation != \"\"]\n",
    "        bug_reports_data[failing_method] = explanations   \n",
    "\n",
    "print(bug_reports_data[\"HIT01_8\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground truth explanations\n",
    "with open(\"ground_truth_explanations.json\", \"r\") as f:\n",
    "    ground_truth_explanations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT03_6: 64.75\n",
      "HIT05_35: 58.62\n",
      "HIT07_33: 53.04\n",
      "HIT02_24: 51.18\n",
      "HIT04_7: 50.16\n",
      "HIT08_54: 46.81\n",
      "HIT06_51: 43.02\n",
      "HIT01_8: 28.67\n",
      "HIT01_8: 22.936\n",
      "HIT02_24: 40.944\n",
      "HIT03_6: 51.8\n",
      "HIT04_7: 40.128\n",
      "HIT05_35: 46.896\n",
      "HIT06_51: 34.416\n",
      "HIT07_33: 42.432\n",
      "HIT08_54: 37.448\n"
     ]
    }
   ],
   "source": [
    "# calculate readability scores for the ground truth explanations\n",
    "\n",
    "import textstat\n",
    "readability_scores = {}\n",
    "for method, explanation in ground_truth_explanations.items():\n",
    "    readability_scores[method] = textstat.flesch_reading_ease(explanation)\n",
    "\n",
    "# sort the explanations by readability\n",
    "sorted_explanations = sorted(readability_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print readibility scores\n",
    "for method, score in sorted_explanations:\n",
    "    print(f\"{method}: {score}\")\n",
    "\n",
    "readability_threshold = {}\n",
    "for method, score in readability_scores.items():\n",
    "    readability_threshold[method] = round(score * 0.8,3)\n",
    "\n",
    "# print readability thresholds\n",
    "for method, score in readability_threshold.items():\n",
    "    print(f\"{method}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bzwad\\anaconda3\\envs\\DSWebscrape\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# define simialrity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load a high-performance model for semantic similarity\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def compute_similarity(ground_truth, user_explanation):\n",
    "    \"\"\"\n",
    "    Computes cosine similarity between the ground truth explanation and a user-given explanation.\n",
    "    \"\"\"\n",
    "    embeddings = model.encode([ground_truth, user_explanation], convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 0.5436896428233012\n",
      "HIT02_24: 0.3701791672501713\n",
      "HIT03_6: 0.25586818529409355\n",
      "HIT04_7: 0.2914702493418008\n",
      "HIT05_35: 0.42632644800469277\n",
      "HIT06_51: 0.30135327534129225\n",
      "HIT07_33: 0.4918408831271032\n",
      "HIT08_54: 0.3938455417131384\n",
      "HIT01_8: 0.7063461601734161\n",
      "HIT02_24: 0.5649046778678893\n",
      "HIT03_6: 0.32944928407669066\n",
      "HIT04_7: 0.38390407562255857\n",
      "HIT05_35: 0.5162835419178009\n",
      "HIT06_51: 0.4160767793655395\n",
      "HIT07_33: 0.6244548857212067\n",
      "HIT08_54: 0.4770480155944824\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity for all user explanations and set threshold\n",
    "similarity_scores = {}\n",
    "\n",
    "for method, ground_truth in ground_truth_explanations.items():\n",
    "    scores = [compute_similarity(ground_truth, user_exp) for user_exp in bug_reports_data.get(method, [])]\n",
    "    similarity_scores[method] = scores\n",
    "\n",
    "# average similarity per failing method\n",
    "average_similarity_scores = {}\n",
    "for method, scores in similarity_scores.items():\n",
    "    average_similarity_scores[method] = sum(scores) / len(scores)\n",
    "\n",
    "for method, score in average_similarity_scores.items():\n",
    "    print(f\"{method}: {score}\")\n",
    "\n",
    "# set similarity threshold to 70th percentile\n",
    "similarity_threshold = {}\n",
    "for method, scores in similarity_scores.items():\n",
    "    similarity_threshold[method] = np.percentile(scores, 70)\n",
    "\n",
    "for method, score in similarity_threshold.items():\n",
    "    print(f\"{method}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import enchant\n",
    "\n",
    "def contains_english_word(text):\n",
    "    \"\"\"\n",
    "    Check if a string contains at least one English word.\n",
    "    Returns True if an English word is found, False otherwise.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input string to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if contains English word, False otherwise\n",
    "    \"\"\"\n",
    "    # Initialize English dictionary\n",
    "    dictionary = enchant.Dict(\"en_US\")\n",
    "    \n",
    "    # Clean the string - keep only letters and spaces\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Split into potential words\n",
    "    words = cleaned_text.split()\n",
    "    \n",
    "    # Check each potential word\n",
    "    return any(dictionary.check(word.lower()) for word in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity of Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q 3.1) There are many different ways which we could use to measure the diversity of explanations. We could, for example, use the type-token ratio or the number of unique words in the explanations to measure the diversity of words used in the explanations. Since we did not get great results with the TTR in previous experiments, we will not use this approach. Instead, we want to regard the Shannon Entropy of the explanations. The Shannon Entropy is a measure of the uncertainty in a random variable. In our case, the random variable is the choice of words in the explanations. The Shannon Entropy is defined as follows:\n",
    "\n",
    "$$H(X) = - \\sum_{i=1}^{n} p(x_i) \\cdot \\log_2(p(x_i))$$\n",
    "\n",
    "where $p(x_i)$ is the probability of the $i$-th word in the explanation. Shannon entropy measures the randomness or uncertainty in a distribution—in this case, the distribution of words in a text. Higher entropy means more unpredictability, while lower entropy suggests redundancy or repetition. The minimum entropy is 0, which occurs when all words are the same. The maximum entropy is the logarithm of the number of words in the text, which occurs when all words are equally likely. For normal written English, entropy usually ranges between 4 and 8 bits per word, depending on vocabulary richness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also measure diversity by looking at the semantic diversity of explanations using the embedding distance (mean pairwise cosine similarity) between the explanations. Since this directly contradicts a high similarity between explanations, we decided against this approach.\n",
    "In the broader range of diversity, we could look at more features than the explanation itself, e.g. at associated categorical features like the bug reporters demographic data, their experience level or the country that they are from. However, this makes it harder to define exact thresholds for diversity.\n",
    "\n",
    "As the Shannon Entropy seems like the most straight forward approach, we will use this to measure the diversity of explanations in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def shannon_entropy(text):\n",
    "    words = text.split()\n",
    "    word_counts = Counter(words)\n",
    "    total_words = len(words)\n",
    "    entropy = -sum((count/total_words) * math.log2(count/total_words) for count in word_counts.values())\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT08_54: 5.358714497742255\n",
      "HIT07_33: 5.25585347326784\n",
      "HIT06_51: 5.115114023681427\n",
      "HIT01_8: 5.10341455748809\n",
      "HIT03_6: 4.999664476749764\n",
      "HIT05_35: 4.898153434632013\n",
      "HIT02_24: 4.8219280948873635\n",
      "HIT04_7: 4.812209613812088\n"
     ]
    }
   ],
   "source": [
    "# calculate shannon entropy for ground truth explanations\n",
    "ground_truth_entropy = {}\n",
    "for method, explanation in ground_truth_explanations.items():\n",
    "    ground_truth_entropy[method] = shannon_entropy(explanation)\n",
    "\n",
    "# sort the explanations by entropy\n",
    "sorted_entropy = sorted(ground_truth_entropy.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print entropy scores\n",
    "for method, score in sorted_entropy:\n",
    "    print(f\"{method}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all our ground truth explanations achieve a Shannon Entropy of 4-6 bits per word. We will use this as a reference point for the diversity of explanations. This moderate Entropy is in general desirable, as it indicates a good balance between clarity and lexical variety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q 3.2) The max readability and max similarity values independent of the diversity per bug report are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 0.820572555065155, 99.23\n",
      "HIT02_24: 0.7392517328262329, 100.24\n",
      "HIT03_6: 0.6439655423164368, 118.18\n",
      "HIT04_7: 0.7673725485801697, 118.18\n",
      "HIT05_35: 0.7223565578460693, 104.64\n",
      "HIT06_51: 0.6698489785194397, 116.15\n",
      "HIT07_33: 0.7574557662010193, 118.18\n",
      "HIT08_54: 0.7468466758728027, 110.06\n"
     ]
    }
   ],
   "source": [
    "# Process all methods in a single pass to find highest similarity and readability scores/explanations\n",
    "highest_similarity_scores = {}\n",
    "highest_readability_scores = {}\n",
    "most_similar_explanations = {}\n",
    "most_readable_explanations = {}\n",
    "\n",
    "for method, explanations in bug_reports_data.items():\n",
    "    # Calculate similarity scores for all explanations\n",
    "    similarity_scores = [compute_similarity(ground_truth_explanations[method], explanation) for explanation in explanations]\n",
    "    max_similarity_index = similarity_scores.index(max(similarity_scores))\n",
    "    \n",
    "    # Store highest similarity score and corresponding explanation\n",
    "    highest_similarity_scores[method] = similarity_scores[max_similarity_index]\n",
    "    most_similar_explanations[method] = explanations[max_similarity_index]\n",
    "    \n",
    "    # Calculate readability scores for all explanations\n",
    "    readability_scores = []\n",
    "    for explanation in explanations:\n",
    "        if len(explanation.split()) == 0 or not contains_english_word(explanation) or len(explanation.split())<4:\n",
    "            readability_scores.append(0)\n",
    "        else:\n",
    "            readability_scores.append(textstat.flesch_reading_ease(explanation))\n",
    "    \n",
    "    max_readability_index = readability_scores.index(max(readability_scores))\n",
    "    \n",
    "    # Store highest readability score and corresponding explanation\n",
    "    highest_readability_scores[method] = readability_scores[max_readability_index]\n",
    "    most_readable_explanations[method] = explanations[max_readability_index]\n",
    "\n",
    "# Print scores\n",
    "for method, (similarity, readability) in zip(highest_similarity_scores.keys(), \n",
    "                                           zip(highest_similarity_scores.values(), \n",
    "                                               highest_readability_scores.values())):\n",
    "    print(f\"{method}: {similarity}, {readability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The readability scores are quite high because some people put very simple \"explanations\" like \"yes\" or \"no\" as their answer. To avoid artificially inflated scores, we filtered out explanations that did not contain English words or were shorter than 4 words.\n",
    "However, the most readable explanations still tend to be very simple answers, indicating that readability alone might not be the best metric to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i++ should be i+\n",
      "I am not sure.\n",
      "type will be object when it should be string\n"
     ]
    }
   ],
   "source": [
    "print(most_readable_explanations[\"HIT07_33\"])\n",
    "print(most_readable_explanations[\"HIT04_7\"])\n",
    "print(most_readable_explanations[\"HIT05_35\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q 3.3) To find the max diversity for the max similarity (compromising readability) we first look directly at the diversity of the methods with the highest similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 4.829966150010236\n",
      "HIT02_24: 4.720049960644813\n",
      "HIT03_6: 6.022673958060609\n",
      "HIT04_7: 5.519999987133631\n",
      "HIT05_35: 6.443530320573129\n",
      "HIT06_51: 5.576098444107486\n",
      "HIT07_33: 4.004886164091841\n",
      "HIT08_54: 5.490861597695111\n"
     ]
    }
   ],
   "source": [
    "entropies = {}\n",
    "\n",
    "for method, explanation in most_similar_explanations.items():\n",
    "    entropies[method] = shannon_entropy(explanation)\n",
    "    print(f\"{method}: {entropies[method]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 4.829966150010236 vs 5.10341455748809 (GT), deviation = 0.27344840747785426\n",
      "HIT02_24: 4.720049960644813 vs 4.8219280948873635 (GT), deviation = 0.10187813424255054\n",
      "HIT03_6: 6.022673958060609 vs 4.999664476749764 (GT), deviation = -1.0230094813108446\n",
      "HIT04_7: 5.519999987133631 vs 4.812209613812088 (GT), deviation = -0.7077903733215436\n",
      "HIT05_35: 6.443530320573129 vs 4.898153434632013 (GT), deviation = -1.545376885941116\n",
      "HIT06_51: 5.576098444107486 vs 5.115114023681427 (GT), deviation = -0.46098442042605914\n",
      "HIT07_33: 4.004886164091841 vs 5.25585347326784 (GT), deviation = 1.2509673091759987\n",
      "HIT08_54: 5.490861597695111 vs 5.358714497742255 (GT), deviation = -0.13214709995285556\n"
     ]
    }
   ],
   "source": [
    "# comparing highest similarity entropies to ground_truth_entropy \n",
    "\n",
    "for method, entropy in entropies.items():\n",
    "    print(f\"{method}: {entropy} vs {ground_truth_entropy[method]} (GT), deviation = {ground_truth_entropy[method]- entropy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for all of these cases the diversity is acceptable, although it is mostly slightly lower than our ground truth. Because of this, we decided to also look at the top 10 most similar explanations for each bug report and calculate the Shannon Entropy for each of them. We also regard combinations of these explanations to find the highest diversity for the highest similarities, i.e. the highest diversity may be achieve by combining the top 5 most similar explanations or by only taking one of the top 10 most similar explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 7.104215726535024, explanations (10): ('The variable \"minutesOffset\" is checked incorrectly by the IF statement on line 279. Any negative value for \"minutesOffset\" will throw this exception; while the documentation states that \"minutesOffset\" can be negative in some cases.', 'There is a logical check for if minuteOffset is less than 0 or greater than 59 causing it to throw an exception because the value is out of bounds (negative number)', 'The code never gets that far. The problem is at line 279 which prevents a negative minutes value being accepted even though the programmer comments indicate that since version 2.3 negative minutes up to -59 are acceptable. The @throws IllegalArgumentException comment is also referring to versions before 2.3.', 'In the code there is a check that 0 <= minutes < 60 and the minutesOffset is -15 which does not fall into these prarmeters thus throwing an Exception', 'The minute variable was negative therefore; it threw the exception because it only takes numbers between 0 and 59 for minutes.', 'YES. The issue is on line 279 (as I explained in my first question; of which I misunderstood that I was only being asked about the specific issue; not generalized issue). On line 279 the variable \"minutesOffSet\" is parameterized to throw an exception if it is < 0 or > 59. Line 279 should read \"if (minutesOffset < -59 || minutesOffset > 59) {\" because now the method can take in the number of minutes as a negative and will allow the method to properly progress to invoke/call further methods such as those asked about in the two previous questions.', 'The argument -15 is less than 0; which causes the if statement conditional on line 279 to pass. This results in the exception on line 280 being thrown. According to the comment block above the method; minutesOffset should be checked for below -59 or above 59.', 'Line 279 written as \"minutesOffset < 0\" makes it clear it\\'s the one throwing the Exception; as the -15 in the minutes spot is clearly less than 0.', 'As noted in the comments; valid input for minutes must be in the rage -59 to +59 but on line 279 of the source minutesOffset is checked for < 0. Instead it should be minutesOFfset < -59 . Also noted in comments is that versions before 2.3 minutes had to be zero or positive. \"Minutes out of range: + minutesOffset\" is our error.', 'I believe the issue is with hoursOffset not minutes')\n",
      "HIT02_24: 6.538425914613637, explanations (8): ('Since the exception seems to be thrown up by Color constructor (seeing message - color parameter outside of expected range); there is a problem with the value of g.', 'depending on the upperBound and lowerBound values; \"g\" might exceed -255 or 255 which is not a valid value for the Color object.', 'variable \"g\" might be outside the range of the Color class acceptable range values.', 'You are calling the Color constructor with three float parameters so the values are allowed to be between 0.0 and 1.0.', 'The variable is being defined correctly as a parameter of the getPaint method.', \"value really only has to be an int since valid values are forced 0 to 255 later.  I imagine it is a double for consistency with other color schemes used in other methods that may use the full range.    but by itself shouldn't cause any problem with any functions used in getPaint\", 'The exception is coming from Color; so it must be g that has a bad value.  I need to see the definition of this.lowerBound and this.upperBound to know what is wrong though.', 'there is an issue with colors in that programme ')\n",
      "HIT03_6: 7.383962289166847, explanations (9): ('I don\\'t see where this calls a method named translate. I haven\\'t used escapeCsv() before. A quick look at the online documentation says \"Returns a String value for a CSV column enclosed in double quotes; if required.\". Hmm. I looked at the source code for escapeCsv() and it calls ESCAPE_CSV.translate(). That isn\\'t this translate tho. And besides that; the string doesn\\'t contain excess commas or quote symbols or newlines. I looked up the two characters and neither appears to be a comma or quote or newline. They both showed up as an unknown character.', \"I'm a little fuzzy on what is going on with this code because I'm not up on all the details of handling unicode but the purpose of this sections seems to be dealing with the fact that in things like UTF-8 sometimes you get characters that are one byte and sometimes 2. Anyway; the issue seems to be with the for loop on line 94. We are incrementing the variable pt and checking that it is less than consumed but we are accessing the input via the pos variable.    If consumed == 0 on line 86 then we increment pos on line 89. Pos appears to always be incremented at a value of greater than or equal to one for every character in the input. The point is that pos gets incremented at a rate faster than characters from the input are consumed and can become longer than the input length which will raise an error on line 95 when consumed is greater than zero.\", \"(just copied my last statement since it applies here as well); StringEscapeUtils is a java constructor with the method escapeCsv; translate isn't even being used at all in the assertion.\", 'as pos gets larger; it will go past CharSequence at given (input; pos)', 'pos is trying to add to itself via charcount of an input that is out of range. ', 'Possibly. If \"pos\" somehow exceeded the length of the input string; I suspect that line 87 would throw the OutOfBounds exception; probably during the call to Character.codePointAt().', 'As I said in my previous answer; I\\'m pretty sure the issue is with one of the Character.codePointAt method calls.  It also would require the \"pos\" variable to reach the value of 2 to have thrown the error listed above.  I can\\'t figure out any way for the \"pos\" variable to reach a value of 2 and still execute another iteration of the loop (which might lead to the execution of line 87 and an exception there).  Each time the \"pos\" variable is changed (potentially to an invalid amount) the continue keyword sends the program back to line 84 where the \"pos\" value is checked against the \"len\" variable for validity.    Therefore; it seems that the only place where the exception could be coming from is line 95.', 'If the codePointAt method returns a unicode character value greater than 0x10000; then charCount returns 2; which would be potentially added to pos to create a larger index value than the string length.', 'The pos counter is being incremented in line 89 and line 95 within the while; so it could be incremented beyond the len variable.')\n",
      "HIT04_7: 7.2594525420748, explanations (9): (\"The failure is caused by the fact that an assertion test was set to 1 on an index fetch on the one time period added to the TimePeriodValues. The index is set to 3; so any index range get function will return 3 at this point corresponding to that one time period's index; which will fail an assertion test looking for a 1. The function in line 299 won't play into this at all.\", 's.add method expects one parameter of type timeperiod - in the test; the s.add method is called with two parameters.', 'At line 301 the argument of \"getDataItem\" should be \"this.maxMiddleIndex\" but is instead \"this.minMiddleIndex\".This call is part of a method that updates bounds for all index variables( \"minStartIndex\"; \"maxStartIndex\"; \"minMiddleIndex\"; etc)and more specifically the section of that code that updates the \"maxMiddleIndex\". Information that was retrieved using the \"getTime\" method erroneously retrieved it from the \"minMiddleIndex\" which led to bounds being updated incorrectly.', 'public void add(TimePeriodValue item) wont get invoked since it takes only one argument whereas the test s.add(new SimpleTimePeriod(0L; 50L); 3.0) has two arguments here; so it means issue is somewhere else.', \"I cannot see the getPeriod(); getStart(); or getTime() methods. It's possible that there is an issue with this line; because it's directly related to calculating the maxMiddleIndex value; but without looking into those methods; there is no way to tell.\", 'The tested code only adds one TimePeriod to the TimePeriodValues instance and therefore updateBounds is only called once at that point.  When called all of the index properties have been initialized to -1 and so therefore the else component of the referenced conditional is executed and the maxMiddleIndex should be correctly set to the input index.', 'line 299 should be:      long s = getDataItem(this.maxMiddleIndex).getPeriod().getStart().getTime();    and line 300 should also be corrected; otherwise there will be another assertion failure:      long e = getDataItem(this.maxMiddleIndex).getPeriod().getEnd().getTime();', 'You want to check for maxMiddleIndex to see if its value makes sense with the updated bounds. However; when calculating the maxMiddleIndex; you use this.minMiddleIndex instead of this.maxMiddleIndex as your index for retrieving the period. This should give you the wrong time span.', 'Line 301 is calling assessor functions to set variables to be used to calculate the MaxMiddleIndex. Since the assertion fails when checking the MaxMiddleIndex it is likely there is something wrong with the assessor functions or how the value they return is being manipulated.')\n",
      "HIT05_35: 7.3686662873826165, explanations (7): ('The type variable being used at line 3290 is set up at line 3288. There we see if array and element both are null; then it is set to Object.class. Object classes are not implicitly converted to Strings because this can fail if the Object does not convert directly to a String (it could; but maybe not - thus the fail).    So; you are expecting an IllegalArgumentException from add; but there is no coding of this. You might try throwing an error instead of using Object.class by default. Something on the lines of:    Class<?> type;  if (array != null) {    type = array.getClass().getComponentType(); // if it isn\\'t an array class; fail  } else if (element != null) {    type = element.getClass(); // build the collection on this type otherwise  } else {    throw new IllegalArgumentException(\"Arguments must not both be null!\");  }', 'ArrayUtils.add() method accepts Object parameters only and not String. So using T type converts your runtime objects to String and not as Objects.  So modify the class to use Objects instead of T type for this operation alone. Use a cast check if required; but stick to Objects for this. Alternatively; you can write your own add() method if you want it to accept String readily.', 'the method public static Object[] add(Object[] array; Object element) Copies the given array and adds the given element at the end of the new array. The new array contains the same elements of the input array plus the given element in the last position. The component type of the new array is the same as that of the input array.    If the input array is null; a new one element array is returned whose component type is the same as the element; unless the element itself is null; in which case the return type is Object[] ==> so we would end up with java.lang.ClassCastException Ljava.lang.Object; cannot be cast to Ljava.lang.String;', 'Yes; type gets set to Object when both parameters to add are null which is what causes the ClassCastException. ', 'I think this could be answered \"Yes\" or \"No\" legitimately.  The locus of the problem seems; to me; to be the choice of using a generic here; and particularly how it was typed in line 3288.  So; in that sense one might say that \"No\" there is not a problem.    However; this line we are examining in this equation; line 3290; does contain the definition of the variable \"newArray\" which is then able to be assigned the \"offending\" Object type.  So in that sense; there IS something wrong here with the use or definition of the variable.', 'I do not believe Class<?> type in line 3288 is responsible for the failure because by writing Class<?>; you are declaring a Class object which can be of any type (? being a wildcard); and the failure is related to an object being casted as a string.  However; my reasoning should be taken with a grain of salt since I am still learning Java code myself after transitioning over from C++ and Matlab', 'I don\\'t think \"type\" is a reserved word in Java.')\n",
      "HIT06_51: 7.411583808146805, explanations (10): ('Yes. The problem is exactly that when we get to line 260 in our code (add(Long.toString(value));); we actually send 0 as an argument to the \"add\" method; not -0.0; because variable \"value\" is defined of type long eliminating our .0 portion of the number and automatically converting the remaining -0 to 0; since it\\'s the same thing to the compiler. As a result; 0 is appended to our string; not -0.0.', 'The lines 257 to 261 are fine in the context of addNumber method written. The failure received above relates to a failure in comparison of two string/string objects due to incompatible formats. The failure above is not caused by any part of source code given below.', 'The problem is that a [-0.] is expected; but not returned. The call to add passes as an argument the string of value that could not be possibly be [-0] as it formerly was a long number; which has no sign on 0. This is the place where the -0. expected might be loss.', 'I doubt this line is relevant either.  It merely adds a number to the string if that number is multiplied by ten with an exponent less than two.  That should have nothing to do with the differences between the two strings listed in the failure.  Neither is off by a great deal; nor do they seemingly have an odd value thrown in.', \"This could be the problem but I suspect the issue is either on line 248 or 263. I suspect java has representations for both -0.0 and 0.0 for floating point numbers but not integers. The code on line 260 may not even get execute because the block starting at line 247 may never be entered. After the explicit conversion to a long and then the implicit conversion back to a double for the comparison I think you may end up with the test 0.0 == -0.0 we I imagine would evaluate to false. If this is the case then line 263 gets executed and I suspect String.valueOf(x) is converting -0.0 to 0.    If the code block on line 247 is entered then I suspect the issue is line 248. I believe longs only have one representation for zero so the cast converts -0.0 to 0. There is a small chance that longs have a -0 value in which case the issue could be with line 260 but I don't think that is the case.\", 'value would be a long; which does not have a decimal place; that is what was happening in the error. There was only 0; no decimal; meaning that x was either not a float; or double; or it was being floored; or ceilinged just be fore the end.', 'See previous answer.  I don\\'t have experience with toString() either; but I guess it must be where the [] is appearing.  I presume this is at line 260 as the exponent would be >2 for a 0; and obvious no \"E\" was printed.', 'The comparison between (long)x == x could cause an error since x is still a double. However; java should convert the double x to a long.  Also; that error would not be the same as the one listed above.', 'The error is in the while loop within the clause which will never be able to exit the loop; for the same reasons I wrote in the first question. Because the error is within the loop; the loop will continue and never reach the end of the method \"addNumber\" and as such the add method will never be called from outside the source code.', 'I don\\'t believe so - (long)x will be equal to x for -0.0. We won\\'t go through the while loop since abs(x) is 0; therefore exp will remain 0. So we will add Long.toString(value); which is Long.toString(0); which should give us \"0\". This seems valid to me.')\n",
      "HIT07_33: 7.111437816846508, explanations (8): (\"A NullPointerException occurs in Java the same as in any other language in that you're pushing something that is valued at null into something that either cannot accept it as such or cannot use it as such and then having it be used incorrectly - with the null value. To me; it seems as if the array variable here is not the problem as the values and methods it's using and dealing with are seemingly valid - but I'm not sure where else in your code the exception is except that the parameters you're passing to these two assert parameter array initializations would be the likely suspect. I was wondering if this toClass method is an overload of the ClassUtils method toClass since you're using the ClassUtils object as the second parameter of your assert here. \", 'I want to say the error of the NullPointerException is caused by these lines of code; as this is where you finally call on the array object; after checking to see if the object itself is null or empty.', \"An object is being passed as an array as a parameter in toClass; so this shouldn't cause the exception.\", 'The second element of our input array is null. When we call the getClass method on null a NullPointerException is raised.', 'I believe index 1 in the array being looped through is a null; so this would cause an exception since getClass expects an object; not null. ', 'I think when it gets to array[i] when I is 1. It references null   So calling getClass() on null will give null pointer exception', \"As we iterate through Object's dimensions; there are null arrays in the middle. getClass doesn't work on nulls and throws a NullPointerException. You might try testing for these nulls at line 910 like so:    classes[i] = array[i] == null ? null : array[i].getClass();\", 'I think that getClass could produce a null pointer error if it were applied to a null; however; I don\\'t see how that would work with this code.  It seems that toClass() only acts on {\"Test\";null;99d}; which is not null (though it contains a null).  That said; I may be misremembering the hierarchy of class/object in Java; so I\\'m very uncertain on this.  (Ie; perhaps toClass() throws an error when it\\'s not in the right place of the hierarchy -- although a null pointer exception would still be hard to explain.)')\n",
      "HIT08_54: 6.927672928261003, explanations (10): ('The fourth character must be the beginning of the country code per the defined format for the string version of locale.  Therefore; characters 3 and 4 represent the country code.  The input is defined strictly requiring these characters to be upper case.  In the test example given; the third character is an underscore (\"_\") which is not allowed.  Therefore; this code threw the proper exception letting the user know that the string input (\"fr__POSIX\") was an incorrect format.', 'LocaleUtils.toLocale(\"fr__POSIX\") creates a Locale object. The parameter \"fr__POSIX\" is passed to the String str variable in line 94. Lines 115 to 117 are validating the fourth and fifth characters of str to ensure that these characters are uppercase letters. If not; it throws an IllegalArgumentException error. This is not the case as the values \"PO\" are valid uppercase letters.', 'The input \\'fr__POSIX\\' is not following the expected format outlined in the javadoc: the fourth character is part of the country code and \"must be uppercase\" (not an underscore)', 'Given that the format of the locale appears to be cc__CCCCC (c for character); the third character of the locale will always contain an underscore. Which in ASCII has a greater value than \\'Z\\' causing the \"ch3 > \\'Z\\'\" portion of the if statement on line 115 to be true and throw the exception.', 'None;this is an expected behavior on the code. This only means that the condition that will determine if the format of the locale value is met throwing the IllegalArgumentExeption error (Invalid locale format). This is because either the 3rd of 4th character in the local value must be an alpha character where the 3rd char is (_) satisfying the condition to throw the error.', 'code condition at 110 is throwing exception.    if (str.charAt(2) != \\'_\\') {                  throw new IllegalArgumentException(\"Invalid locale format: \" + str);              }', \"The comments say it validates strictly.  There is no Country code ... one could argue it's null I guess.   There are consecutive underscores so ch3 is an underscore and not a Capital Letter so the exception is thrown at line 116.\", 'output for the code is due to below statement.    if (str.charAt(2) != \\'_\\') {                  throw new IllegalArgumentException(\"Invalid locale format: \" + str);              }', 'Upper case used for country code; So that the string is in invalid format that the result is IllegalArgumentException.', 'None; this is an expected behavior of the code. This only means that the condition to check if the 3rd or 4th characters are invalid characters (non-alpha characters) in the locale value. ')\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "top10_similar_explanations = {}\n",
    "for method, explanations in bug_reports_data.items():\n",
    "    similarity_scores = [compute_similarity(ground_truth_explanations[method], explanation) for explanation in explanations]\n",
    "    top10_indices = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)[:10]\n",
    "    top10_similar_explanations[method] = [explanations[i] for i in top10_indices]\n",
    "\n",
    "# find the combination with the highest shannon entropy per bug report\n",
    "highest_entropy = {}\n",
    "highest_entropy_explanations = {}\n",
    "\n",
    "for method, explanations in top10_similar_explanations.items():\n",
    "    max_entropy = 0\n",
    "    max_entropy_explanations = []\n",
    "    \n",
    "    # Check combinations of different lengths\n",
    "    for length in range(1, len(explanations) + 1):\n",
    "        for combination in combinations(explanations, length):\n",
    "            combined_text = \" \".join(combination)\n",
    "            entropy = shannon_entropy(combined_text)\n",
    "            if entropy > max_entropy:\n",
    "                max_entropy = entropy\n",
    "                max_entropy_explanations = combination\n",
    "    \n",
    "    highest_entropy[method] = max_entropy\n",
    "    highest_entropy_explanations[method] = max_entropy_explanations\n",
    "\n",
    "# print highest entropy scores\n",
    "for method, (score, explanations) in zip(highest_entropy.keys(), \n",
    "                                           zip(highest_entropy.values(), \n",
    "                                               highest_entropy_explanations.values())):\n",
    "    print(f\"{method}: {score}, explanations ({len(explanations)}): {explanations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIT01_8: 59.39300000000001\n",
      "HIT02_24: 67.53\n",
      "HIT03_6: 65.34555555555555\n",
      "HIT04_7: 49.75888888888889\n",
      "HIT05_35: 70.2457142857143\n",
      "HIT06_51: 78.22\n",
      "HIT07_33: 62.59375\n",
      "HIT08_54: 56.3\n"
     ]
    }
   ],
   "source": [
    "# determine average readability scores for the highest entropy explanations\n",
    "highest_entropy_readability = {}\n",
    "for method, explanations in highest_entropy_explanations.items():\n",
    "    readability_scores = [textstat.flesch_reading_ease(explanation) for explanation in explanations]\n",
    "    highest_entropy_readability[method] = sum(readability_scores) / len(readability_scores)\n",
    "\n",
    "# print highest entropy readability scores\n",
    "for method, score in highest_entropy_readability.items():\n",
    "    print(f\"{method}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach seems to favor multiple and thus slightly longer explanations. With this, we reach rather high entropy scores. This is a good sign, as it indicates that the explanations are diverse and not just repetitions of the same information. The average readability is a bit low, however, this is a trade-off that we are willing to make to ensure that the explanations are diverse. We would also expect this value to increase when feeding the explanations to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Combining these insights with our previous results for task 2, it seems logical to curate a set of ~10 explanations for each bug report, which are the most similar to the ground truth and have a high diversity. This way, we can ensure that the explanations are both accurate and diverse. Since readability already comes to some extend with the similarity, it can be neglected or only slightly optimized for. We can also imagine that the readability can easily be tweaked by prompting the LLM to generate more readable explanations, while similar approaches to similarity and diversity are not as straight forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSWebscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
